defaults:
    - env: mbpo_ant
    - obs_enc: proprio_identity # proprio_MLP, pixel_CNN
    - hydra/launcher: submitit

experiment: test

replay_buffer_capacity: max(${num_train_steps}, 1e6)
# replay_buffer_capacity: ${num_train_steps}

num_seed_steps: 1000

eval_freq: 10000
num_eval_episodes: 10
fixed_eval: true

normalize_obs: ??? # Set by obs_enc

device: cuda
action_repeat: 1

log_freq: 10000
log_save_tb: false

save_video: false
delete_replay_at_end: true

save_freq: 100000
save_best_eval: true
save_zfill: 7

seed: 1

# For debugging:
num_initial_states: null # Use a subset of initial states
max_episode_steps: null # If set, use shorter episodes

model_free_hidden_dim: 512
model_free_hidden_depth: 4
obs_dim: ???
action_dim: ???
action_range: ???

agent:
  name: sac_mve
  class: agent.sac_mve.SACMVEAgent
  params:
    env_name: ${env_name}
    obs_dim: ${obs_dim}
    latent_obs_dim: ${latent_obs_dim}
    action_dim: ${action_dim}
    action_range: ${action_range}
    device: ${device}
    dx_cfg: ${dx}
    num_train_steps: ${num_train_steps}

    train_with_policy_mean: false
    train_action_noise: 0.0

    obs_encoder_cfg: ${obs_encoder_cfg}
    obs_decoder_cfg: ${obs_decoder_cfg}
    obs_ae_lr: 5e-4
    obs_latent_penalty: 0.
    obs_latent_step_penalty: 0.
    obs_recon_penalty: 0.

    temp_cfg: ${learn_temp}

    actor_cfg: ${normal_actor}
    actor_lr: 1e-4
    actor_betas: [0.9, 0.999]
    actor_update_freq: 1
    actor_num_sample: 1
    actor_clip_grad_norm: null # 5.0
    actor_mve: true
    actor_detach_rho: false

    critic_cfg: ${double_q_critic}
    critic_lr: 1e-4
    # TODO: Have a separate \tau for the encoder?
    critic_tau: 0.005
    critic_target_update_freq: 1
    critic_clip_grad_norm: null # 5.0
    critic_target_mve: false

    discount: 0.99
    seq_batch_size: 512
    step_batch_size: 1024
    horizon: 3
    seq_train_length: ${agent.params.horizon}
    update_freq: 1

    model_update_freq: 1
    model_update_repeat: 1

    model_free_update_repeat: 1

    rew_obs_noise: 0.
    done_obs_noise: 0.
    done_obs_repeat: 1

    rew_hidden_dim: 512
    rew_hidden_depth: 2
    rew_lr: 1e-3

    done_hidden_dim: 512
    done_hidden_depth: 2
    done_lr: 1e-3
    done_ctrl_accum: true

    act_with_horizon: false
    warmup_steps: 0 # Auto-set if null

    det_suffix: 0.0


dx:
  name: dx
  class: common.dx.SeqDx
  params:
    env_name: ${env_name}
    obs_dim: ${latent_obs_dim}
    action_dim: ${action_dim}
    action_range: ${action_range}
    horizon: ${agent.params.horizon}
    device: ${device}
    detach_xt: true
    xu_enc_hidden_dim: 512
    xu_enc_hidden_depth: 2
    x_dec_hidden_dim: 512
    x_dec_hidden_depth: 0
    clip_grad_norm: 1.0
    rec_type: GRU
    rec_latent_dim: 512
    rec_num_layers: 2
    lr: 1e-3

normal_actor:
  class: agent.actor.NormalActor
  params:
    obs_dim: ${latent_obs_dim}
    action_dim: ${action_dim}
    hidden_dim: ${model_free_hidden_dim}
    hidden_depth: ${model_free_hidden_depth}
    log_std_bounds: [-5, 2]

double_q_critic:
  class: agent.critic.DoubleQCritic
  params:
    obs_dim: ${latent_obs_dim}
    action_dim: ${action_dim}
    hidden_dim: ${model_free_hidden_dim}
    hidden_depth: ${model_free_hidden_depth}

learn_temp:
  class: common.temp.LearnTemp
  params:
    init_temp: 0.1
    max_steps: ${num_train_steps}
    init_targ_entr: -${action_dim}
    final_targ_entr: -${action_dim}
    entr_decay_factor: 0.
    only_decrease_alpha: false
    lr: 1e-4
    device: ${device}


hydra:
    name: ${env_name}
    run:
        dir: ./exp/local/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}
    sweep:
        dir: ./exp/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}
        subdir: ${hydra.job.num}
    launcher:
        # Defaults: https://github.com/fairinternal/hydra-fair-plugins/blob/master/plugins/hydra-submitit/hydra_plugins/submitit/conf/hydra/launcher/submitit.yaml
        params:
            queue_parameters:
                slurm:
                    max_num_timeout: 100000
                    time: 4319
                    partition: learnfair
                    # partition: priority
                    # comment: For ICML

        mem_limit: 64
